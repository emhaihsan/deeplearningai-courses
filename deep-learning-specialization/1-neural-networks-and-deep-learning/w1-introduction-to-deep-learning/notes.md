### What is Neural Network?

- Deep Learning refers to training Neural Networks, which can be very large.
- A Neural Network is a model used for various tasks; here, the example is Housing Price Prediction.
- Linear regression is initially used to predict house prices based on size, but adjustments are made to ensure realistic predictions.
- A basic neural network is illustrated with a single neuron, taking the size of the house as input and predicting the price as output.
- The neuron uses a ReLU (rectified linear unit) function, common in neural network literature.
- Larger neural networks are formed by stacking multiple neurons together, creating a more complex model.
- Additional features like number of bedrooms, family size, zip code, and wealth are introduced to enhance predictions.
- These features are processed by individual neurons, contributing to the overall prediction of house prices.
- The neural network has an input layer (with features) and hidden layers that are densely connected.
- Neural networks, given enough training data, can learn to accurately map inputs to outputs.
- The focus is on supervised learning, where the network learns to map input $(x)$ to output $(y)$.

### Supervised Learning with Neural Network

- **Introduction to Neural Networks:**
  - Hype surrounding neural networks and their effectiveness.
  - Emphasis on economic value from supervised learning.

- **Supervised Learning Basics:**
  - Definition of supervised learning: input x, output y.
  - Examples include housing price prediction and online advertising.

- **Applications of Neural Networks:**
  - Online advertising as a lucrative application.
  - Advances in computer vision, speech recognition, machine translation, and autonomous driving.

- **Neural Network Architectures:**
  - Different architectures for various applications.
  - Standard neural networks, convolutional neural networks (CNN), and recurrent neural networks (RNN).

- **Structured vs. Unstructured Data:**
  - Structured data involves well-defined features (e.g., housing data).
  - Unstructured data includes audio, images, and text; improved interpretation by neural networks.

- **Economic Value of Neural Networks:**
  - Short-term economic value in structured data (e.g., advertising systems).
  - Recognition of neural network successes in unstructured data.
 
### Why is Deep Learning Taking Off
- Deep learning's recent success is attributed to the increase in available data and the ability to train larger neural networks.
- The digitization of society has led to a significant growth in digital data, thanks to activities on computers, websites, mobile apps, and IoT devices.
- The performance of traditional learning algorithms like support vector machines plateaus as data increases, while deep neural networks continue to improve with more data.
- The key factors for achieving high performance in deep learning are the scale of both the neural network (size of hidden units and parameters) and the amount of data.
- In smaller training sets, the relative ordering of algorithms is less defined, and performance relies on skill in feature engineering.
- In the big data regime, large neural networks consistently outperform other approaches.
- Initially, the rise of deep learning was driven by scaled data and computation, enabling the training of very large neural networks.
- Algorithmic innovations, such as the shift from sigmoid to ReLU activation functions, have played a crucial role in accelerating learning and improving computation efficiency.
- Fast computation is essential for rapid experimentation, allowing practitioners and researchers to iterate on ideas quickly.
- Ongoing forces, such as the continuous growth of digital data, advancements in specialized hardware (e.g., GPUs), and ongoing algorithmic innovations, suggest that deep learning will continue to improve in the future.
